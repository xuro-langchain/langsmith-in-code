{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiturn Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll show how to create more advanced multiturn simulations with LangGraph, and subsequently evaluate the multiturn interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicated evaluations require a more complex agent than our simple ELI5 workflow in the basics folder. We've defined a multiagent that acts as a customer service assistant for a fictional music store.\n",
    "\n",
    "This customer service assistant consists of a supervisor and two subagents: an invoice subagent and a music subagent. The invoice subagent handles billing related requests, while the music subagent handles music related requests. The supervisor handles routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent import multiagent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "from langsmith import Client # Set up LangSmith client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementation details, see the multiagent.py file. Tools accessible to our subagents are available in the multiagent_tools.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Multiple Turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the openevals package maintained by LangChain to simulate a user interaction with our multiagent. During our run function, we'll take in a starting question and a user description to seed the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a dataset with sample questions and expected output trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"simulated_user_prompt\": \"\"\"\n",
    "            You are a user browsing the music catalog of a digital music store.\n",
    "            You are a big fan of Queen, but are exploring some other genres. \n",
    "            After at maximum 2 other genres, you should ask for rock recommendations.\n",
    "            If any songs by Queen are returned, you should ask for songs by Queen.\n",
    "            \"\"\",\n",
    "            \"seed_messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"What opera songs do you have?\"},\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"trajectory\": [\n",
    "                {'role': 'user', 'content': 'What opera songs do you have?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'We have one opera song:\\n\\n• \"Die Zauberflöte, K.620: \\'Der Hölle Rache Kocht in Meinem Herze\\'\"\\n\\nLet me know if you\\'d like additional details about this performance.'}, \n",
    "                {'role': 'user', 'content': 'Thanks for the opera suggestion! Could you also recommend some jazz songs?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some jazz songs available from our catalog:\\n\\n• \"OAM\\'s Blues\" – by Aaron Goldberg  \\n• \"Amanda\" – by Aisha Duo  \\n• \"Desafinado\" – by Antônio Carlos Jobim  \\n• \"Quadrant\" – by Billy Cobham  \\n• \"Roll Call\" – by Dennis Chambers  \\n• \"Jeepers Creepers\" – by Gene Krupa\\n\\nLet me know if you\\'d like additional details about any of these tunes!'}, \n",
    "                {'role': 'user', 'content': \"Thanks for the jazz options! Now I'd like some rock song recommendations, please.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some rock song recommendations from our catalog:\\n\\n• \"For Those About To Rock (We Salute You)\" – by AC/DC  \\n• \"Balls to the Wall\" – by Accept  \\n• \"All I Really Want\" – by Alanis Morissette  \\n• \"Money\" – by BackBeat  \\n• \"Susie Q\" – by Creedence Clearwater Revival\\n\\nLet me know if you\\'d like more details about any of these tracks!'},\n",
    "                {'role': 'user', 'content': 'Thanks for the rock recommendations! Do you have any songs by Queen available?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"It looks like we don't have any songs by Queen in our catalog at the moment. Can I help you explore another artist or perhaps a different style?\"},\n",
    "                {'role': 'user', 'content': \"Since Queen songs aren't available, could you recommend some classic rock songs or bands similar to Queen?\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some classic rock options from our catalog that carry a similar energy to Queen:\\n\\n• \"For Those About To Rock (We Salute You)\" – by AC/DC  \\n• \"Walk On Water\" – by Aerosmith  \\n• \"Susie Q\" – by Creedence Clearwater Revival\\n\\nThese selections offer a powerful rock vibe and captivating showmanship reminiscent of Queen\\'s style. Let me know if you\\'d like more information on any of these tracks!'}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"simulated_user_prompt\": \n",
    "            \"\"\"\n",
    "            You are a user who had a bad experience with a digital music store.\n",
    "            You should insult the customer service assistant once before continuing the conversation.\n",
    "            You want to know how much your most recent purchase was.\n",
    "            Your customer ID is 1, but you will not provide this information unless asked. \n",
    "            \"\"\",\n",
    "            \"seed_messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"You guys really suck.\"},\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"trajectory\": [\n",
    "                {'role': 'user', 'content': 'You guys really suck.'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"I'm sorry to hear that you're upset. Your feedback is important to us, and I'd like to understand what went wrong so we can address your concerns. Could you please provide more details about the issue you're experiencing or what you'd like help with?\"}, \n",
    "                {'role': 'user', 'content': \"I want to know how much my most recent purchase was. Don't ask me for my customer ID unless you really need it.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'I need your customer ID to locate and review your invoice details. Could you please provide your customer ID?'}, \n",
    "                {'role': 'user', 'content': 'Fine, my customer ID is 1. Now, can you tell me how much my last purchase was?'},\n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Thank you for providing your customer ID. I’ve verified your account details, and your most recent purchase, made on 2025-08-07, was for $8.91. Is there anything else I can help you with today?'}, \n",
    "                {'role': 'user', 'content': \"Thanks for the info. That's all I needed for now.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"You're welcome! I'm glad I could help. If you have any more questions, please don't hesitate to reach out. Have a great day!\"}, \n",
    "                {'role': 'user', 'content': 'Yeah, whatever. Goodbye.'}, \n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_name = \"Evals: Multiturn\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs=[ex[\"inputs\"] for ex in examples],\n",
    "        outputs=[ex[\"outputs\"] for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a run function for our multiagent that is compatible with the openevals run_multiturn_simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.types import ChatCompletionMessage\n",
    "from multiagent import multiagent\n",
    "# Running simulation requires a func that takes in a chat message (dict with \"role\" and \"content\" keys) and a thread_id as a kwarg\n",
    "# This function should return a chat message as output with at least role and content keys (other keys optional)\n",
    "def run_multiagent(message: ChatCompletionMessage, *, thread_id: str, **kwargs):\n",
    "    res = multiagent.invoke(\n",
    "        {\"messages\": [message]}, \n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    return res[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define a run function for our evaluation, that can take in dataset inputs and use the examples to seed our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.simulators import run_multiturn_simulation, create_llm_simulated_user\n",
    "\n",
    "\n",
    "def run_simulation(inputs: dict):\n",
    "    # Create a simulated user with seeded messages and system prompt from our dataset\n",
    "    user = create_llm_simulated_user(\n",
    "        system=inputs[\"simulated_user_prompt\"],\n",
    "        model=\"openai:gpt-4.1-mini\",\n",
    "        fixed_responses=inputs[\"seed_messages\"],\n",
    "    )\n",
    "\n",
    "    # Next, let's use openevals to run a simulation with our multiagent\n",
    "    simulator_result = run_multiturn_simulation(\n",
    "        app=run_multiagent,\n",
    "        user=user,\n",
    "        max_turns=5,\n",
    "    )\n",
    "\n",
    "    # Return the full conversation trajectory as an output\n",
    "    return {\"trajectory\": simulator_result[\"trajectory\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run our simulation function to see what the outputs look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What opera songs do you have?\n",
      "assistant: We currently have the following opera song in our catalog:\n",
      "\n",
      "• \"Die Zauberflöte, K.620: 'Der Hölle Rache Kocht in Meinem Herze'\" performed by Sir Georg Solti, Sumi Jo & Wiener Philharmoniker\n",
      "\n",
      "If you'd like more recommendations or additional details about this piece, please let us know!\n",
      "user: Thanks for the opera recommendation! Could you suggest some jazz songs next?\n",
      "assistant: Here are some jazz songs from our catalog:\n",
      "\n",
      "• \"OAM's Blues\" by Aaron Goldberg  \n",
      "• \"Amanda\" by Aisha Duo  \n",
      "• \"Desafinado\" by Antônio Carlos Jobim  \n",
      "• \"Quadrant\" by Billy Cobham  \n",
      "• \"Roll Call\" by Dennis Chambers  \n",
      "• \"Jeepers Creepers\" by Gene Krupa  \n",
      "• \"Doce De Carnaval (Candy All)\" by Gilberto Gil  \n",
      "• \"Colibri\" by Incognito\n",
      "\n",
      "If you need more details about any of these songs or additional recommendations, please let me know!\n",
      "user: Thank you for the jazz selections! Now, could you please recommend some rock songs?\n",
      "assistant: Here are some rock songs from our catalog:\n",
      "\n",
      "• \"For Those About To Rock (We Salute You)\" by AC/DC  \n",
      "• \"Balls to the Wall\" by Accept  \n",
      "• \"Walk On Water\" by Aerosmith  \n",
      "• \"All I Really Want\" by Alanis Morissette  \n",
      "• \"We Die Young\" by Alice In Chains  \n",
      "• \"Cochise\" by Audioslave  \n",
      "• \"Money\" by BackBeat  \n",
      "• \"Susie Q\" by Creedence Clearwater Revival\n",
      "\n",
      "If you'd like more details about any of these tracks or need further recommendations, please let me know!\n",
      "user: Great rock selections! Do you have any songs by Queen available? I'd love to check them out.\n",
      "assistant: Here are the Queen songs available in our catalog:\n",
      "\n",
      "• \"A Kind Of Magic\"  \n",
      "• \"Under Pressure\"  \n",
      "• \"Radio GA GA\"  \n",
      "• \"I Want It All\"  \n",
      "• \"I Want To Break Free\"  \n",
      "• \"Innuendo\"  \n",
      "• \"It's A Hard Life\"  \n",
      "• \"Breakthru\"  \n",
      "• \"Who Wants To Live Forever\"  \n",
      "• \"Headlong\"  \n",
      "• \"The Miracle\"  \n",
      "• \"I'm Going Slightly Mad\"  \n",
      "• \"The Invisible Man\"  \n",
      "• \"Hammer To Fall\"  \n",
      "• \"Friends Will Be Friends\"  \n",
      "• \"The Show Must Go On\"  \n",
      "• \"One Vision\"  \n",
      "• \"Bohemian Rhapsody\"  \n",
      "• \"Another One Bites The Dust\"  \n",
      "• \"Killer Queen\"  \n",
      "• \"Fat Bottomed Girls\"  \n",
      "• \"Bicycle Race\"  \n",
      "• \"You're My Best Friend\"  \n",
      "• \"Don't Stop Me Now\"  \n",
      "• \"Save Me\"  \n",
      "• \"Crazy Little Thing Called Love\"  \n",
      "• \"Somebody To Love\"  \n",
      "• \"Now I'm Here\"  \n",
      "• \"Good Old-Fashioned Lover Boy\"  \n",
      "• \"Play The Game\"  \n",
      "• \"Flash\"  \n",
      "• \"Seven Seas Of Rhye\"  \n",
      "• \"We Will Rock You\"  \n",
      "• \"We Are The Champions\"  \n",
      "• \"Sheer Heart Attack\"  \n",
      "• \"All Dead, All Dead\"  \n",
      "• \"Spread Your Wings\"  \n",
      "• \"Fight From The Inside\"  \n",
      "• \"Get Down, Make Love\"  \n",
      "• \"Sleep On The Sidewalk\"  \n",
      "• \"Who Needs You\"  \n",
      "• \"It's Late\"  \n",
      "• \"My Melancholy Blues\"\n",
      "\n",
      "Let me know if you need more details about any track or if you'd like further recommendations!\n",
      "user: Awesome! Could you suggest some of the top Queen songs from the list, maybe their most iconic hits?\n",
      "assistant: Based on the list, here are a few of Queen's most iconic hits you might enjoy:\n",
      "\n",
      "• Bohemian Rhapsody  \n",
      "• We Will Rock You  \n",
      "• We Are The Champions  \n",
      "• Another One Bites The Dust  \n",
      "• Don't Stop Me Now  \n",
      "• Killer Queen\n",
      "\n",
      "Each of these tracks has made a significant impact on music history. Let me know if you’d like more details on any of these songs or further recommendations!\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_trajectory(trajectory):\n",
    "    for message in trajectory:\n",
    "        print(f\"{message['role']}: {message['content']}\")\n",
    "\n",
    "results = run_simulation(examples[0][\"inputs\"])\n",
    "pretty_print_trajectory(results[\"trajectory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create an LLM as a Judge to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "\n",
    "model = ChatOpenAI(model=\"o3-mini\")\n",
    "\n",
    "judge_prompt = \"\"\"\n",
    "You are a helpful assistant that evaluates the quality of a customer service assistant's response to a customer's request.\n",
    "You will be given a conversation between a customer and a customer service assistant.\n",
    "\n",
    "High quality customer service assistant responses:\n",
    "- Are helpful and informative\n",
    "- Are concise and to the point\n",
    "- Are professional and respectful\n",
    "\n",
    "Low quality customer service assistant responses:\n",
    "- Are rude or dismissive\n",
    "- Ignore the customer's request without reasonable justification\n",
    "- Are not helpful or informative\n",
    "\n",
    "Provided is the conversation\n",
    "<conversation>\n",
    "{conversation}\n",
    "</conversation>\n",
    "\n",
    "Also provided is a reference conversation that represents a high quality customer service.\n",
    "<reference_conversation>\n",
    "{reference_conversation}\n",
    "</reference_conversation>\n",
    "\n",
    "Please evaluate the quality of the customer service assistant's responses based on the rubric provided.\n",
    "\"\"\"\n",
    "\n",
    "class Helpfulness(TypedDict):\n",
    "    \"\"\"Compare the reference conversation and actual conversation and measure the helpfulness of the customer service assistant.\"\"\"\n",
    "    reasoning: Annotated[str, ..., \"Explain your reasoning for whether the actual response is correct or not.\"]\n",
    "    helpful: Annotated[bool, ..., \"True if the customer service assistant is helpful, otherwise False.\"]\n",
    "\n",
    "\n",
    "def helpfulness(inputs: dict, outputs: dict, reference_outputs: dict):\n",
    "    conversation = outputs[\"trajectory\"]\n",
    "    reference_conversation = reference_outputs[\"trajectory\"]\n",
    "\n",
    "    judge_llm = model.with_structured_output(Helpfulness)\n",
    "    results = judge_llm.invoke(judge_prompt.format(conversation=conversation, reference_conversation=reference_conversation))\n",
    "    return results[\"helpful\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to run some evaluations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertxu/Desktop/Projects/education/eval-concepts/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'multiagent-multiturn-2965628b' at:\n",
      "https://smith.langchain.com/o/bcad64b4-50f8-4e66-a0be-8dbaf6f6619c/datasets/9cd552dd-a2fd-4cd6-b8e6-52b931deb7cd/compare?selectedSessions=3d0e8653-0d07-4307-a561-874a2bc3a1c7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:19, 39.50s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Evals: Multiturn\"\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    run_simulation,\n",
    "    data=dataset_name,\n",
    "    evaluators=[helpfulness],\n",
    "    experiment_prefix=\"multiagent-multiturn\",\n",
    "    num_repetitions=1,\n",
    "    max_concurrency=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
